{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is for loading the data and installing relevant librarys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: Impact of Review Scores on Price\n",
    "\n",
    "Null Hypothesis (H0): Review scores (e.g., cleanliness, location, communication) do not significantly affect the listing price.\n",
    "\n",
    "Alternative Hypothesis (H1): Higher review scores lead to higher listing prices.\n",
    "\n",
    "EDA Approach: Calculate correlations between review scores and price. Fit a multiple linear regression model (e.g., price ~ cleanliness + location_score + communication_score).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we aim to investigate the relationship between review scores and listing prices in the context of a rental property marketplace. The overarching question we seek to address is whether higher review scores, encompassing factors such as cleanliness, location, and communication, correspond to higher listing prices. Our null hypothesis (H0) posits that review scores do not significantly affect listing prices, while the alternative hypothesis (H1) suggests that higher review scores lead to higher listing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA):\n",
    "To explore the relationship between review scores and listing prices, we employ various techniques aimed at understanding the data distribution and identifying correlations. These techniques include:\n",
    "\n",
    "Calculating Correlations: We compute correlations between review scores (e.g., cleanliness, location, communication) and listing prices. This helps us understand the strength and direction of the relationship between these variables.\n",
    "\n",
    "Fitting a Multiple Linear Regression Model: We fit a multiple linear regression model, where the listing price is the dependent variable, and review scores are the independent variables. This model allows us to quantify the impact of each review score on the listing price while controlling for other factors.\n",
    "\n",
    "Calculating Spearman's Rank Correlation: Spearman's rank correlation coefficient, is a statistical method used to determine the strength and direction of the relationship between two ordinal(Ordinal refers to categorical data with a specific order or ranking. In our analysis, review scores (e.g., cleanliness, location) are examples of ordinal variables because they can be ranked from lowest to highest.) variables. It's particularly useful when dealing with ordinal data, where the actual numerical differences between values may not be meaningful. This method ensures robustness against outliers and non-linear relationships, providing reliable insights into the association between variables in our analysis.\n",
    "\n",
    "Calculating Summary Statistics: We compute summary statistics, including mean, median, standard deviation, minimum, maximum, and quartiles, for both review scores and listing prices. These statistics provide insights into the central tendency and variability of the data.\n",
    "\n",
    "Visualizations: We create various visualizations, including box plots, scatter plots, and histograms, to further explore the distribution and relationships within the data. Box plots help us visualize the distribution of review scores and their relationship with listing prices. Scatter plots provide insights into the linear relationship between review scores and listing prices, while histograms offer a visual representation of the distribution of review scores and listing prices individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1108\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1379\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1379\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/datasets/mrnabiz/detailed-airbnb-listing-data-london-sep-2022/data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd              # For data manipulation\n",
    "import numpy as np               # For numerical operations\n",
    "import matplotlib.pyplot as plt # For plotting graphs\n",
    "import seaborn as sns            # For enhanced visualization\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.linear_model import LinearRegression    # For linear regression modeling\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # For model evaluation metrics\n",
    "\n",
    "# Set backend for matplotlib to TkAgg for interactive plotting\n",
    "# Note: This line may not be necessary if you're not using an interactive backend\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "# Specify the file path\n",
    "file = '/Users/olisa/Downloads/clean_df.csv'  # Update file path as needed\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TkAgg\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the interactive backend has been set right\n",
    "import matplotlib\n",
    "print(matplotlib.get_backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is cleaning the dataframe and removing the colums that are not neccsary for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'listing_url', 'name', 'description', 'neighborhood_overview',\n",
      "       'host_id', 'host_url', 'host_name', 'host_since', 'host_location',\n",
      "       'host_about', 'host_response_time', 'host_response_rate',\n",
      "       'host_acceptance_rate', 'host_is_superhost', 'host_picture_url',\n",
      "       'host_listings_count', 'host_total_listings_count',\n",
      "       'host_verifications', 'host_identity_verified',\n",
      "       'neighbourhood_cleansed', 'latitude', 'longitude', 'property_type',\n",
      "       'room_type', 'accommodates', 'bathrooms_text', 'bedrooms', 'beds',\n",
      "       'amenities', 'price', 'minimum_nights', 'maximum_nights',\n",
      "       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'first_review', 'last_review',\n",
      "       'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     price  review_scores_rating  review_scores_accuracy  \\\n",
      "0   $50.00                  4.90                    4.82   \n",
      "1   $75.00                  4.79                    4.84   \n",
      "2   $90.00                  4.32                    4.53   \n",
      "3   $55.00                  4.84                    4.91   \n",
      "4  $379.00                  4.74                    4.82   \n",
      "\n",
      "   review_scores_cleanliness  review_scores_checkin  \\\n",
      "0                       4.89                   4.86   \n",
      "1                       4.88                   4.87   \n",
      "2                       4.03                   4.72   \n",
      "3                       4.71                   4.93   \n",
      "4                       4.69                   4.69   \n",
      "\n",
      "   review_scores_communication  review_scores_location  review_scores_value  \n",
      "0                         4.93                    4.75                 4.82  \n",
      "1                         4.82                    4.93                 4.73  \n",
      "2                         4.86                    4.72                 4.31  \n",
      "3                         4.93                    4.92                 4.83  \n",
      "4                         4.69                    4.88                 4.59  \n"
     ]
    }
   ],
   "source": [
    "# Creating a list of relevant columns for analysis\n",
    "relevant_columns = ['price', 'review_scores_rating', 'review_scores_accuracy', \n",
    "                    'review_scores_cleanliness', 'review_scores_checkin', \n",
    "                    'review_scores_communication', 'review_scores_location',\n",
    "                    'review_scores_value']\n",
    "\n",
    "# Creating a subset of the original DataFrame with only the relevant columns\n",
    "subset_data = data[relevant_columns]\n",
    "\n",
    "# Display the first 5 rows of the new DataFrame\n",
    "print(subset_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check and potentially handle any missing values and convert any datatypes if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price                           object\n",
      "review_scores_rating           float64\n",
      "review_scores_accuracy         float64\n",
      "review_scores_cleanliness      float64\n",
      "review_scores_checkin          float64\n",
      "review_scores_communication    float64\n",
      "review_scores_location         float64\n",
      "review_scores_value            float64\n",
      "dtype: object\n",
      "price                              7\n",
      "review_scores_rating           16785\n",
      "review_scores_accuracy         17807\n",
      "review_scores_cleanliness      17794\n",
      "review_scores_checkin          17841\n",
      "review_scores_communication    17808\n",
      "review_scores_location         17839\n",
      "review_scores_value            17842\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the data types of columns in the subset DataFrame\n",
    "print(subset_data.dtypes)\n",
    "\n",
    "# Print the number of missing values in each column of the subset DataFrame\n",
    "print(subset_data.isna().sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have confirmed that there are some missing values so we will need to fix that. In addition price is in the wrong type so lets convert it to a neumeric one. After that we will proceed with some Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there are a significant amount of missing values for the review score we will have to 'drop' these rows from the dataframe entirely.\n",
    "\n",
    "subset_data = subset_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         50.0\n",
      "1         75.0\n",
      "2         90.0\n",
      "3         55.0\n",
      "4        379.0\n",
      "         ...  \n",
      "69346     55.0\n",
      "69347    201.0\n",
      "69348    246.0\n",
      "69349    250.0\n",
      "69350    134.0\n",
      "Name: price, Length: 51505, dtype: float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Remove commas from the 'price' column\n",
    "subset_data['price'] = subset_data['price'].str.replace(',', '')\n",
    "\n",
    "# Remove dollar sign ('$') from the 'price' column\n",
    "subset_data['price'] = subset_data['price'].str.replace('$', '')\n",
    "\n",
    "# Convert the 'price' column to float datatype\n",
    "subset_data['price'] = subset_data['price'].astype(float)\n",
    "\n",
    "# Print the 'price' column and its datatype after conversion\n",
    "print(subset_data['price'])\n",
    "print(subset_data['price'].dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price                          float64\n",
      "review_scores_rating           float64\n",
      "review_scores_accuracy         float64\n",
      "review_scores_cleanliness      float64\n",
      "review_scores_checkin          float64\n",
      "review_scores_communication    float64\n",
      "review_scores_location         float64\n",
      "review_scores_value            float64\n",
      "dtype: object\n",
      "price                          0\n",
      "review_scores_rating           0\n",
      "review_scores_accuracy         0\n",
      "review_scores_cleanliness      0\n",
      "review_scores_checkin          0\n",
      "review_scores_communication    0\n",
      "review_scores_location         0\n",
      "review_scores_value            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking that we have succesfully cleaned the data\n",
    "\n",
    "# Check if all data types are float64\n",
    "if subset_data.dtypes.eq('float64').all():\n",
    "    # Check if there are no missing values\n",
    "    if subset_data.isna().sum().sum() == 0:\n",
    "        print(\"Data successfully cleaned.\")\n",
    "    else:\n",
    "        print(\"Error: Missing values detected after cleaning.\")\n",
    "else:\n",
    "    print(\"Error: Data types not successfully converted to float64.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 157.2412330841666\n",
      "median = 99.0\n",
      "standard deviation = 296.7888059691308\n",
      "variance = 88083.59534858238\n",
      "min = 0.0\n",
      "max = 23000.0\n",
      "q25 = 56.0\n",
      "q75 = 171.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics for the 'price' column\n",
    "\n",
    "# Mean\n",
    "mean_price = subset_data['price'].mean()\n",
    "\n",
    "# Median\n",
    "median_price = subset_data['price'].median()\n",
    "\n",
    "# Standard Deviation\n",
    "std_price = subset_data['price'].std()\n",
    "\n",
    "# Variance\n",
    "var_price = subset_data['price'].var()\n",
    "\n",
    "# Minimum and Maximum\n",
    "min_price = subset_data['price'].min()\n",
    "max_price = subset_data['price'].max()\n",
    "\n",
    "# Quartiles\n",
    "q25_price = subset_data['price'].quantile(0.25)\n",
    "q75_price = subset_data['price'].quantile(0.75)\n",
    "\n",
    "# Store summary statistics in a list\n",
    "summ_stats = [(f'mean = {mean_price}'), (f'median = {median_price}'), \n",
    "              (f'standard deviation = {std_price}'), (f'variance = {var_price}'), \n",
    "              (f'min = {min_price}'), (f'max = {max_price}'), \n",
    "              (f'q25 = {q25_price}'), (f'q75 = {q75_price}')]\n",
    "\n",
    "# Print each summary statistic\n",
    "for stat in summ_stats:\n",
    "    print(stat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean: The mean listing price is $157.24, indicating the average price of listings in the dataset.\n",
    "\n",
    "Median: The median listing price is $99.00. This suggests that half of the listings have prices below $99.00 and half have prices above $99.00.\n",
    "\n",
    "Standard Deviation: The standard deviation of $296.79 tells us how much each listing price deviates, on average, from the mean price of $157.24., the standard deviation is relatively high, thus it means that listing prices vary widely around the average, indicating a broader range of prices.\n",
    "\n",
    "Variance: The variance of $88083.60, being the square of the standard deviation, provides a measure of the overall variability or spread of listing prices from the mean. A high variance suggests that listing prices are widely spread out from the mean, indicating a diverse range of prices within the dataset\n",
    "\n",
    "Minimum: The minimum listing price is $0.00, which suggests the presence of listings with no cost or possibly outliers.\n",
    "\n",
    "Maximum: The maximum listing price is $23000.00, indicating the highest price in the dataset.\n",
    "\n",
    "25th Percentile (Q1): The 25th percentile, is $56.00. This means that 25% of listings have prices below $56.00.\n",
    "\n",
    "75th Percentile (Q3): The 75th percentile,  is $171.00. This means that 75% of listings have prices below $171.00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These stats on there own are not very useful so lets do some more work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we are going to start with data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot - A boxplot provides a concise summary of the distribution of the data, including measures such as the median, quartiles, and potential outliers. Here's how you can create a boxplot for the 'price' variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/2819812101.py:7: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='price', data=subset_data, palette='pastel')\n"
     ]
    }
   ],
   "source": [
    "# Create a boxplot to visualize the distribution of prices\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the boxplot\n",
    "sns.boxplot(x='price', data=subset_data, palette='pastel')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot of Price')\n",
    "plt.xlabel('Price')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots vizualize the relationship between review score and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1262879487.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n"
     ]
    }
   ],
   "source": [
    "# Create scatter plots to visualize the relationship between each review score and the listing price\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Creating a list of review score columns\n",
    "review_scores = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', \n",
    "                 'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "                 'review_scores_value']\n",
    "\n",
    "# Iterate over each review score and create a scatter plot\n",
    "for score in review_scores:\n",
    "    sns.scatterplot(x=score, y='price', data=subset_data, palette='pastel')\n",
    "    plt.xlabel(f'Review Score ({score.replace(\"review_scores_\", \"\")})')\n",
    "    plt.ylabel('Listing Price')\n",
    "    plt.title(f'Impact of {score} on Listing Price')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms show us the frequency distribution of the given variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
      "/var/folders/26/p92lw58s64l1zlyt8yg13ztc0000gn/T/ipykernel_19536/1750981394.py:13: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n"
     ]
    }
   ],
   "source": [
    "# Create histograms to visualize the distribution of each review score\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Creating a list of review score columns\n",
    "review_scores = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', \n",
    "                 'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "                 'review_scores_value']\n",
    "\n",
    "# Iterate over each review score and create a histogram\n",
    "for score in review_scores:\n",
    "    sns.histplot(x=score, data=subset_data, bins=10, palette='pastel')\n",
    "    plt.xlabel(f'Review Score ({score.replace(\"review_scores_\", \"\")})')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'Distribution of {score}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter graphs reveal a moderately strong correlation between review scores and listing prices. This suggests that higher review scores are associated with higher listing prices, supporting the hypothesis that better-reviewed properties tend to command higher prices.\n",
    "\n",
    "One valuable insight from the histograms is the distribution of review scores among the properties. The predominance of ratings at 4 and 5 stars indicates that the majority of properties receive high ratings from guests. This could suggests that the properties listed in your dataset generally provide satisfactory experiences for guests, which could positively influence their pricing and overall desirability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of summary statstics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis - using Spearmans rank\n",
    "Spearman's rank correlation is a way to see if there's a pattern between these two factors (in this case it will be price and a review score)\n",
    "The stronger the correlation (closer to 1 or -1), the more closely review scores and prices are connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's Rank Correlation for review_scores_rating:\n",
      "Correlation Coefficient: -0.015812341544848587\n",
      "P-value: 0.00033232744870826764\n",
      "\n",
      "Spearman's Rank Correlation for review_scores_accuracy:\n",
      "Correlation Coefficient: -0.044544580908478904\n",
      "P-value: 4.786891612422521e-24\n",
      "\n",
      "Spearman's Rank Correlation for review_scores_cleanliness:\n",
      "Correlation Coefficient: 0.018445622110721985\n",
      "P-value: 2.8336935429981428e-05\n",
      "\n",
      "Spearman's Rank Correlation for review_scores_checkin:\n",
      "Correlation Coefficient: -0.0626855392342194\n",
      "P-value: 5.1754473558540985e-46\n",
      "\n",
      "Spearman's Rank Correlation for review_scores_communication:\n",
      "Correlation Coefficient: -0.06263411655087699\n",
      "P-value: 6.118655276762388e-46\n",
      "\n",
      "Spearman's Rank Correlation for review_scores_location:\n",
      "Correlation Coefficient: 0.14657953741885937\n",
      "P-value: 2.963534779491126e-245\n",
      "\n",
      "Spearman's Rank Correlation for review_scores_value:\n",
      "Correlation Coefficient: -0.16359875053693257\n",
      "P-value: 8.42714947732203e-306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary library for Spearman's rank correlation\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Dictionary to store correlation coefficients and p-values for each review score\n",
    "correlation_results = {}\n",
    "\n",
    "# Iterating over each review score variable\n",
    "for score in review_scores:\n",
    "    # Calculating Spearman's rank correlation coefficient between the review score and prices\n",
    "    spearman_corr, p_value = spearmanr(subset_data[score], subset_data['price'])\n",
    "    \n",
    "    # Storing correlation coefficient and p-value in the dictionary\n",
    "    correlation_results[score] = {'correlation_coefficient': spearman_corr, 'p_value': p_value}\n",
    "\n",
    "# Printing the results\n",
    "for score, result in correlation_results.items():\n",
    "    print(f\"Spearman's Rank Correlation for {score}:\")\n",
    "    print(\"Correlation Coefficient:\", result['correlation_coefficient'])\n",
    "    print(\"P-value:\", result['p_value'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Spearman's rank correlation coefficients using a heatmap\n",
    "\n",
    "# Extract correlation coefficients from the dictionary\n",
    "correlation_coefficients = [[correlation_results[score]['correlation_coefficient'] for score in review_scores]]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(correlation_coefficients, annot=True, cmap='coolwarm', xticklabels=review_scores, yticklabels=['Price'], fmt=\".2f\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Spearman's Rank Correlation Coefficients between Review Scores and Price\")\n",
    "plt.xlabel('Review Scores')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Coefficient: This value indicates the strength and direction of the relationship between review scores and listing prices. A correlation coefficient closer to 1 or -1 suggests a strong positive or negative correlation, respectively, while a value closer to 0 indicates a weaker correlation. For example, a correlation coefficient of -0.016 for review_scores_rating suggests a very weak negative correlation between rating scores and listing prices.\n",
    "\n",
    "P-value: This tells us the probability of observing such a correlation coefficient by random chance alone, assuming the null hypothesis is true (i.e., no correlation). A small p-value (typically below 0.05) indicates that the observed correlation is unlikely to be due to random chance, suggesting that there is a significant relationship between the variables. For instance, a p-value of 0.00033 for review_scores_rating suggests a significant correlation between rating scores and listing prices.\n",
    "\n",
    "Review Scores Rating: There is a very weak negative correlation between review scores rating and listing prices, but it is statistically significant.\n",
    "\n",
    "Review Scores Accuracy: There is a weak negative correlation between accuracy scores and listing prices, and it is statistically significant.\n",
    "\n",
    "Review Scores Cleanliness: There is a weak positive correlation between cleanliness scores and listing prices, and it is statistically significant.\n",
    "\n",
    "Review Scores Check-in: There is a moderate negative correlation between check-in scores and listing prices, and it is statistically significant.\n",
    "\n",
    "Review Scores Communication: There is a moderate negative correlation between communication scores and listing prices, and it is statistically significant.\n",
    "\n",
    "Review Scores Location: There is a strong positive correlation between location scores and listing prices, and it is statistically significant.\n",
    "\n",
    "Review Scores Value: There is a strong negative correlation between value scores and listing prices, and it is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Spearman's rank correlation results we will omit certain features. We do this to fine tune the linear regression model and for other benefits such as: Improved interpretability, Simplification of the model :\n",
    "\n",
    "Review Scores Rating: This feature has a very weak negative correlation with listing prices and a relatively high p-value (0.00033). While statistically significant, the correlation coefficient is close to zero, suggesting a negligible effect on listing prices.\n",
    "\n",
    "Review Scores Accuracy: Similar to the rating scores, accuracy scores exhibit a weak negative correlation with listing prices but with a statistically significant p-value (4.79e-24). However, the correlation coefficient is relatively small (-0.044), indicating a minor impact on prices.\n",
    "\n",
    "Review Scores Cleanliness: While cleanliness scores show a weak positive correlation with listing prices, the correlation coefficient (0.018) is small, and the p-value (2.83e-05) is statistically significant. Considering the weak correlation, this feature may not significantly contribute to predicting prices.\n",
    "\n",
    "Review Scores Communication: Communication scores demonstrate a moderate negative correlation with listing prices, but with a statistically significant p-value (6.12e-46). However, the correlation coefficient (-0.063) suggests a relatively modest influence on prices compared to other features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 92082.93\n",
      "R-squared: 0.01\n",
      "                  Feature  Coefficient\n",
      "0   review_scores_checkin   -52.506745\n",
      "1  review_scores_location    95.160796\n",
      "2     review_scores_value   -61.526620\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (X) and target variable (y)\n",
    "features = ['review_scores_checkin', 'review_scores_location', 'review_scores_value']\n",
    "X = subset_data[features]\n",
    "y = subset_data['price']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R-squared: {r2:.2f}')\n",
    "\n",
    "# Interpretation (coefficients)\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(coefficients)\n",
    "\n",
    "# Set Seaborn color palette to pastel\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "# Visualization (actual vs. predicted)\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Regression Model: Actual vs. Predicted Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model aimed to predict listing prices based on review scores, including cleanliness, location, value, check-in experience, communication, and overall rating. However, the model's performance was poor, with a high mean squared error (MSE) of 92082.93 and a low R-squared value of 0.01, indicating limited predictive accuracy. Coefficients revealed minimal impact of review scores on listing prices, suggesting the need for model refinement. Lets try again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By minimizing the RMSE, we are aiming to improve the accuracy of our model's predictions regarding listing prices.\n",
    "Minimizing RMSE helps achieve this by fine-tuning the model's parameters to better capture the relationships between review scores and listing prices in the dataset. Ultimately, a lower RMSE indicates that the model's predictions are closer to the actual listing prices, making it more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define objective function to minimize (RMSE)\n",
    "def rmse_objective(params):\n",
    "    # Fit linear regression model with given parameters\n",
    "    model = LinearRegression()\n",
    "    X_train_subset = X_train.drop(columns=['review_scores_checkin', 'review_scores_value'])\n",
    "    model.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    X_test_subset = X_test.drop(columns=['review_scores_checkin', 'review_scores_value'])\n",
    "    y_pred = model.predict(X_test_subset)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse\n",
    "\n",
    "# Set initial guess for parameters\n",
    "initial_guess = [1.0] * len(X_train.columns)\n",
    "\n",
    "# Run optimization\n",
    "optimized_params = minimize(rmse_objective, initial_guess, method='Nelder-Mead')\n",
    "\n",
    "# Extract optimized parameters\n",
    "optimized_features = optimized_params.x\n",
    "\n",
    "# Fit linear regression model with optimized parameters\n",
    "model = LinearRegression()\n",
    "X_train_subset = X_train.drop(columns=['review_scores_checkin', 'review_scores_value'])\n",
    "model.fit(X_train_subset, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "X_test_subset = X_test.drop(columns=['review_scores_checkin', 'review_scores_value'])\n",
    "y_pred = model.predict(X_test_subset)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Interpretation (coefficients)\n",
    "coefficients = pd.DataFrame({'Feature': X_train_subset.columns, 'Coefficient': model.coef_})\n",
    "\n",
    "# Visualization (actual vs. predicted)\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Regression Model: Actual vs. Predicted Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of this project, where we aimed to analyze the impact of review scores on listing prices, the scatter plot showing the disparity between actual and predicted prices highlights a crucial issue. It suggests that our current multiple linear regression model, despite incorporating various review scores as features, fails to accurately predict listing prices. This discrepancy could potentially invalidate our hypothesis regarding the influence of review scores on prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, our analysis focused on investigating the impact of review scores on listing prices in the context of our project. We began by formulating hypotheses, with the null hypothesis stating that review scores do not significantly affect listing prices, and the alternative hypothesis proposing that higher review scores lead to higher prices. Through exploratory data analysis (EDA), we employed various techniques such as correlation analysis, linear regression modeling, and visualization to examine the relationship between review scores and prices.\n",
    "\n",
    "Our EDA revealed several key findings. Firstly, Spearman's rank correlation analysis indicated significant correlations between certain review scores (e.g., location, cleanliness) and listing prices, suggesting a potential influence of these factors on pricing decisions. However, the linear regression model yielded less promising results, with a high mean squared error (MSE) and low R-squared value, indicating poor model fit and predictive performance. Despite attempts to optimize the model using techniques like minimizing root mean squared error (RMSE), the model's predictions remained inconsistent with the actual prices.\n",
    "\n",
    "Furthermore, visualizations such as box plots, scatter plots, and histograms provided additional insights into the distribution and relationship of review scores and prices. While scatter plots exhibited moderately strong correlations between review scores and prices, the box plots and histograms did not offer significant value due to data skewness and lack of variability in certain variables.\n",
    "\n",
    "In conclusion, while our analysis provided some evidence supporting the influence of review scores on listing prices, the predictive capabilities of our models were limited. Our findings corroborate the null hypothesis, indicating that review scores may not have a significant impact on listing prices. Future research could explore alternative modeling techniques, feature engineering, or additional variables to improve the accuracy and robustness of price prediction models in the vacation rental industry. Additionally, incorporating qualitative factors such as property amenities, location characteristics, and guest reviews could offer a more comprehensive understanding of pricing dynamics in the market."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
